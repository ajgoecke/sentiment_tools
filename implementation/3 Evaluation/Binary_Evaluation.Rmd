---
title: "Binary Evaluation"
output: html_notebook
---

The notebook calculates the Accuracy and F1 score for the binary test condition. It also asses whether the performance differences are statistically significant

```{r}
library(caret) 
library(plyr)
library(dplyr)
library (janitor)
```


```{r}
#Load Scores of the Lexica

ama<- read.csv("../results/sentiment_scores/amazon_sent_norm1.csv")

parl<- read.csv("../results/sentiment_scores/parlvote_sent_norm1.csv")


rev<- read.csv("../results/sentiment_scores/reviews_sent_norm1.csv")

twitter <-read.csv("../results/sentiment_scores/twitter_bin_norm1.csv")

fin <- read.csv("../results/sentiment_scores/finance_bin_norm1.csv")
```



```{r}
#The function calculates the choosen metrics for the dataframe
#In: Dataframe, Flags for choosen metric
#Out: A list of results:
#1: The confusion matrix
#2: The F1 score
#3: The accuracy score
get_metrics <- function(frame,f1=FALSE,matrix=FALSE,accuracy=FALSE) {

  
#The gold labels are the ratings of the frame (pre normalised to -1 and 1)
gold<-frame[,"rating"]
 

#make a subframe of only the lexica values
names <- c("afinn", "lsd", "vader")
names<-frame[names]


conf <- vector(mode = "list", length = 0) 
acc <- vector(mode = "list", length = 0) 
Fone <- vector(mode = "list", length = 0) 



for(i in 1:ncol(names)) {
  
  #normalise the rating of the lexica
 
  pred<-names[,i]
  pred[pred>0] <- 1
  pred[pred<=0] <- -1
  
  
  
  if(matrix==TRUE){
    
    hold<-do.call(rbind, Map(data.frame, pred=pred,  gold=gold))
   
    conf<-table(hold$pred, hold$gold)
    
  }
  
  
  
  if(accuracy==TRUE){
    right = as.integer(0) 
    wrong=as.integer(0)
    
    
    for (i in 1:length(pred)) { 
      if (pred[i]==gold[i]){
        right=right+1}
      
      if (pred[i]!=gold[i]){
        wrong=wrong+1}
      }
   
   acc_score<-right/(right+wrong)
   acc<-c(acc,acc_score) 
  }
  
  
  
  if (f1==TRUE){
  
  pred<-as.factor(pred)
  gold<-as.factor(gold)
  
  precision <- posPredValue(pred, gold, positive="1")
  recall <- sensitivity(pred, gold, positive="1")

  F1 <- (2 * precision * recall) / (precision + recall)
  Fone <- c(Fone, F1)
  
  }
} 

result <- list( conf, Fone,acc )
 
return (result)

}
```


```{r}
#The function takes the output of "get_metrics" and combines the dataframes of the different corpora into one dataframe.
#The number indicates which metric is choosen:
##1: The confusion matrix
#2: The F1 score
#3: The accuracy score

get_comb_metric<-function(ama,rev,parl,twit,fin,num){
  
ama<-ama[num]

rev<-rev[num]

parl<-parl[num]

twit<-twit[num]

fin<-fin[num]


ama<-llply(ama, unlist)
rev<-llply(rev, unlist)
parl<-llply(parl, unlist)
twit<-llply(twit, unlist)
fin<-llply(fin, unlist)

comb<-do.call(rbind, Map(data.frame, ama=ama, books=rev, parl=parl,twitter=twit,finance=fin))
names <- c("afinn", "lsd", "vader")

comb$id <- names 

comb<-comb[,c(6,1,2,3,4,5)]

return (comb)
}


```


```{r}

#Rating normalisation

#values choosen by best performance
ama$rating[ama$rating<3] <- -1
ama$rating[ama$rating>2] <- 1

rev$rating[rev$rating<3] <- -1
rev$rating[rev$rating>2] <- 1



#Get choosen per Corpus metrics
metrics_ama<-get_metrics(ama,matrix=TRUE,f1=TRUE,accuracy = TRUE)

metrics_parl<-get_metrics(parl,f1=TRUE,accuracy = TRUE)

metrics_reviews<-get_metrics(rev,f1=TRUE,accuracy = TRUE)

metrics_twitter<-get_metrics(twitter,f1=TRUE,accuracy = TRUE)

metrics_fin<-get_metrics(fin,f1=TRUE,accuracy = TRUE)

```


```{r}

#Combine the performance metrics into one easily readable frame

acc_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,3)


hold<-acc_comb[c("ama","books","twitter","finance","parl")]

#Calculate the mean performance
acc_comb$average<-rowMeans(hold)
stats <- summarize_all(acc_comb, mean)


#clean up
stats$id<-"Mean of column"
stats<-stats[,c(7,1,2,3,4,5,6)]
acc_comb <- rbind(acc_comb, stats)



f1_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,2)

hold<-f1_comb[c("ama","books","twitter","finance","parl")]

#Calculate the mean performance
f1_comb$average<-rowMeans(hold)
stats <- summarize_all(f1_comb, mean)


#clean up
stats$id<-"Mean of column"
stats<-stats[,c(7,1,2,3,4,5,6)]
f1_comb <- rbind(f1_comb, stats)


#shows the average performance for the choosen condition
print("Average Accuracy")
print(acc_comb[4,7])
print("Average F1")
print(f1_comb[4,7])

```

```{r}
#if needed save results

#setwd("~/Studium/3 Semester/PM/Acc_F1_configs")

#saveRDS(acc_comb,file="config3_bin_norm1_acc.rds")
#saveRDS(f1_comb,file="config3_bin_norm1_f1.rds")
```


ANOVA and Tukey

Lexica
```{r}
#Sort the frames by the lexicas for ANOVA
acc_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,3)


acc_t<-t(acc_comb)
acc_t<-acc_t%>%
row_to_names(row_number = 1)
acc_t <- as.data.frame(acc_t)
st_acccorp <- stack(acc_t)

res.aov <- aov(values ~ ind, data = st_acccorp)
summary(res.aov)

print("----------------------------")
print("Tukey")
TukeyHSD(res.aov)
```

F1
```{r}
#Sort the frames by the lexicas for ANOVA
f1_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,2)


f1_t<-t(f1_comb)
f1_t<-f1_t%>%
row_to_names(row_number = 1)
f1_t <- as.data.frame(f1_t)
st_f1corp <- stack(f1_t)

res.aov <- aov(values ~ ind, data = st_f1corp)
summary(res.aov)

print("----------------------------")
print("Tukey")
TukeyHSD(res.aov)
```



Corpora
```{r}
acc_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,3)
acc_co <- data.frame(acc_comb[,-1], row.names = acc_comb[,1])
st_acc <- stack(acc_co)


res.aov <- aov(values ~ ind, data = st_acc)
summary(res.aov)

print("----------------------------")
print("Tukey")
TukeyHSD(res.aov)
```

F1
```{r}
f1_comb<-get_comb_metric(metrics_ama,metrics_reviews,metrics_parl,metrics_twitter,metrics_fin,2)
f1_co <- data.frame(f1_comb[,-1], row.names = f1_comb[,1])
st_f1 <- stack(f1_co)


res.aov <- aov(values ~ ind, data = st_f1)
summary(res.aov)

print("----------------------------")
print("Tukey")
TukeyHSD(res.aov)
```

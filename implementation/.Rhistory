geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
# apply lexicoder lexicon
series$lsd <- textstat_polarity(tokens(series$text), data_dictionary_LSD2015)$sentiment %>%
ggplot(aes(chapter, sentiment, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
# apply lexicoder lexicon
series %>%
series$lsd <- textstat_polarity(tokens(series$text), data_dictionary_LSD2015)$sentiment %>%
ggplot(aes(chapter, sentiment, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
# apply lexicoder lexicon
series %>%
series$lsd <- textstat_polarity(tokens(series$text), data_dictionary_LSD2015)$sentiment %>%
# ggplot(aes(chapter, sentiment, fill = book)) + # plot sentiment of books
#  geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
# facet_wrap(~ book, ncol = 2, scales = "free_x") +
#ggtitle("LSD HP")
series_tokenized %>%
group_by(book, chapter) %>% # group df by book and chapter to get sentiment per chapter
#series_tokenized$sentiment <- textstat_polarity(series_tokenized$tokens, data_dictionary_LSD2015)$sentiment %>%
summarise(sentiment = textstat_polarity(series_tokenized$tokens, data_dictionary_LSD2015)$sentiment) %>%
#summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "LSD") %>% # add column with method
ggplot(aes(chapter, sentiment, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
# apply lexicoder lexicon
series %>%
series$lsd <- textstat_polarity(tokens(series$text), data_dictionary_LSD2015)$sentiment #%>%
series.df <- to.data.frame(series)
# apply lexicoder lexicon
series$lsd <- textstat_polarity(tokens(series$text), data_dictionary_LSD2015)$sentiment
series.df <- as.data.frame(series)
plot <- ggplot(series.df, aes(chapter, sentiment, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
plot
series.df
plot <- ggplot(series.df, aes(chapter, lsd, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
plot
plot <- ggplot(series, aes(chapter, lsd, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("LSD HP")
plot
get_vader(philosophers_stone[1])
# load required libraries
# to use harry potter dataset
# devtools::install_github("bradleyboehmke/harrypotter")
# devtools::install_github("quanteda/quanteda.sentiment")
# devtools::install_github("quanteda/quanteda.corpora")
library(quanteda)
library(readtext)
library(corpus)
library(tidyverse)
library(stringr)
library(tidytext)
library(harrypotter)
library(janeaustenr)
library(dplyr)
library(quanteda.sentiment)
library(vader)
# load required libraries
# to use harry potter dataset
# devtools::install_github("bradleyboehmke/harrypotter")
# devtools::install_github("quanteda/quanteda.sentiment")
# devtools::install_github("quanteda/quanteda.corpora")
library(quanteda)
library(readtext)
library(corpus)
library(tidyverse)
library(stringr)
library(tidytext)
library(harrypotter)
library(janeaustenr)
library(dplyr)
library(quanteda.sentiment)
library(vader)
require(quanteda)
require(quanteda.corpora)
require(quanteda.sentiment)
hp1_tokenized[[1]];
#hp1_tokenized[[1]]
get_vader(philosophers_stone[1])
hp1_vader
hp1_vader["compopund"]
hp1_vader[hp1_vader["compopund"]]
hp1_vader$compound
series
# apply lexicoder lexicon
series$vader <- vader_df(series$text)$compund
# apply vader lexicon to all HP books
series$vader <- vader_df(series$text)$compound
View(series)
View(series)
library(quanteda)
library(readtext)
setwd("/Users/Anna/Documents/uni/sentiment_tools/implementation")
reviews <- readtext("datasets/goodreads_reviews_children.json", text_field = "review_text")
install.packages("rjson")
library(rjson)
review_file <- "/Users/Anna/Documents/uni/sentiment_tools/implementation/datasets/goodreads_reviews_children.json"
review_df <- fromJSON(paste(readLines(review_file), collapse=""))
review_df <- fromJSON(file = review_file)
library(jsonlite)
reviews <- fromJSON(review_file, flatten=TRUE)
reviews <- fromJSON(review_file)
review_file <- "/Users/Anna/Documents/uni/sentiment_tools/implementation/datasets/test.json"
reviews <- fromJSON(review_file)
reviews <- readtext("datasets/test.json", text_field = "review_text")
reviews <- readtext("datasets/test.json", text_field = "review_text")
review_file <- "/Users/Anna/Documents/uni/sentiment_tools/implementation/datasets/goodreads_reviews_children.json"
reviews <- fromJSON(review_file)
review_file <- "/Users/Anna/Documents/uni/sentiment_tools/implementation/datasets/goodreads_reviews_children_1.json"
reviews <- fromJSON(review_file)
reviews <- readtext("datasets/goodreads_reviews_children_1.json", text_field = "review_text")
reviews <- readtext("datasets/goodreads_reviews_children_2.json", text_field = "review_text")
reviews
reviews
typeof(reviews)
reviews.df <- as.data.frame(reviews)
revies.df
reviews.df <- as.data.frame(reviews)
reviews.df
reviews <- readtext("datasets/goodreads_reviews_children_2.json", text_field = "review_text")
reviews.df <- as.data.frame(reviews)
reviews.df
# Afinn
reviews.df$text.head()
reviews.df
# Afinn
reviews.df
# tokenize
reviews_tokenized <- reviews.df %>%
unnest_tokens(tokens, text)
reviews_sample <- reviews.df[sample(1:nrow(reviews.df), 50,
replace=FALSE),]
reviews_sample
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
#group_by(book, chapter) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ book, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
#group_by(book, chapter) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
#group_by(book, chapter) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_sample %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews <- readtext("datasets/goodreads_reviews_children_2.json", text_field = "review_text")
reviews.df$index <- 1:nrow(reviews.df)
reviews.df
reviews_sample <- reviews.df[sample(1:nrow(reviews.df), 50,
replace=FALSE),]
reviews_sample
reviews.df[1:50]
reviews_50 <- head(reviews.df,50)
reviews_50
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = index)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews.df <- as.data.frame(reviews)
reviews.df$doc_id <- 1:nrow(reviews.df)
reviews.df
# get first 50 rows of data
reviews_50 <- head(reviews.df,50)
reviews_50
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") #%>% # add column with method
v
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# apply lexicoder lexicon
reviews_50$lsd <- textstat_polarity(tokens(reviews_50$text), data_dictionary_LSD2015)$sentiment
#series.df <- as.data.frame(series)
plot <- ggplot(reviews_50, aes(doc_id, lsd, fill = book)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("Lexicoder Reviews")
plot
# apply lexicoder lexicon
reviews_50$lsd <- textstat_polarity(tokens(reviews_50$text), data_dictionary_LSD2015)$sentiment
#series.df <- as.data.frame(series)
plot <- ggplot(reviews_50, aes(doc_id, lsd, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("Lexicoder Reviews")
plot
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(reviews50_sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(reviews50$sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
reviews_tokenized$sentiment = mean(mean(afinn2, na.rm = TRUE) %>%
#summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
reviews_tokenized$sentiment = mean(afinn2, na.rm = TRUE) %>%
#summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
#reviews_tokenized$sentiment = mean(afinn2, na.rm = TRUE) %>%
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized
reviews_tokenized %>%
summarise(sentiment = mean(afinn2), na.rm=TRUE)
reviews_tokenized %>%
summarise(sentiment = mean(afinn2, na.rm=TRUE))
reviews_tokenized %>%
group_by(doc_id) %>%
summarise(sentiment = mean(afinn2, na.rm=TRUE))
reviews_tokenized %>%
group_by(doc_id) %>%
summarise(afinn_sentiment = mean(afinn2, na.rm=TRUE)) %>%
summarise(lsd_sentiment = mean(lsd, na.rm=TRUE))
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
#reviews_tokenized$sentiment = mean(afinn2, na.rm = TRUE) %>%
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
reviews_tokenized %>%
group_by(doc_id) %>%
summarise(afinn_sentiment = mean(afinn2, na.rm=TRUE)) %>%
# summarise(lsd_sentiment = mean(lsd, na.rm=TRUE))
# Afinn
# tokenize
reviews_tokenized <- reviews_50 %>%
unnest_tokens(tokens, text)
# apply afinn lexicon
reviews_tokenized$afinn2 <- textstat_valence(reviews_tokenized$tokens, afinn2)$sentiment
# replace all 0 values with na
reviews_tokenized[reviews_tokenized == 0] <- NA
reviews_tokenized %>%
group_by(doc_id) %>% # group df by book and chapter to get sentiment per chapter
#reviews_tokenized$sentiment = mean(afinn2, na.rm = TRUE) %>%
summarise(sentiment = mean(afinn2, na.rm = TRUE)) %>% # calculate mean w/o regarding na values
mutate(method = "AFINN") %>% # add column with method
ggplot(aes(doc_id, sentiment, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("AFINN Reviews")
#reviews_tokenized %>%
# group_by(doc_id) %>%
#summarise(afinn_sentiment = mean(afinn2, na.rm=TRUE)) %>%
# summarise(lsd_sentiment = mean(lsd, na.rm=TRUE))
reviews_50$vader <- vader_df(reviews_50$text)$compound
plot <- ggplot(reviews_50, aes(doc_id, vader, fill = doc_id)) + # plot sentiment of books
geom_bar(alpha = 0.8, stat = "identity", show.legend = FALSE) +
#facet_wrap(~ doc_id, ncol = 2, scales = "free_x") +
ggtitle("Vader Reviews")
plot
reviews.df
library(textcat)
library(textcat)
```
textcat("This is an English sentence.")
reviews <- readtext("datasets/goodreads_reviews_children_2.json", text_field = "review_text")
reviews.corpus <- corpus(reviews)
reviews.corpus
reviews_en <- corpus_subset(reviews.corpus, language == "english", drop_docid = TRUE)
docvars(reviews.corpus, "language") <- textcat(reviews.corpus)
reviews_en <- corpus_subset(reviews.corpus, language == "english", drop_docid = TRUE)
review_en
reviews_en <- corpus_subset(reviews.corpus, language == "english", drop_docid = TRUE)
reviews_en
reviews.df
reviews.df$language <- textcat(reviews.df$text)
reviews.df

---
title: "Preprocessing the data sets"
---
ParlVote Corpus
```{r}
ParlVote_concat <- read.csv("~/Studium/3 Semester/PM/Corpora/ParlVote_concat.csv")
```


```{r}
library(quanteda)
library(readtext)
library(rjson)
library(jsonlite)
```


```{r}
#only use relevant columns and throw out entries with non ascii characters
red_parl_vote<- subset(ParlVote_concat, select = c("speech","vote"))
red_parl_vote <-red_parl_vote[which(!grepl("[^\x01-\x7F]+",red_parl_vote$speech)),]
```

KinderbÃ¼cher Rezensionen Corpus

```{r}
setwd("/Users/rike-/Documents/Studium/3 Semester/PM/sentiment_tools-main/sentiment_tools-main/implementation")

reviews <- readtext("goodreads_reviews_children_2.json", text_field = "review_text")

```


```{r}
#filter for languages and create a subset of 100 entries each 
reviews$language <- textcat(reviews$text)
total <- data.frame(text=character(),
                 rating=integer(), 
                 stringsAsFactors=FALSE) 
for (i in 0:5){
hold<- subset(reviews, rating == i| language=="english", select = c("text","rating"))
hold1<-hold[sample(nrow(hold), 100), ]
total <- rbind( total, hold1)
}

```

Kyoto Corpus
```{r}
setwd("/Users/rike-/Documents/Studium/3 Semester/PM/kyoto texts/kyoto texts/")
#read in kyoto table
kyoto <- read.csv('kyoto_editorials_all.csv')


```



